{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple tutorial [link](https://medium.com/@mishra.thedeepak/doc2vec-simple-implementation-example-df2afbbfbad5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the dependencies\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\"love apple juice\",\n",
    "        \"love orange juice\",\n",
    "        \"miss Soviet Union\",\n",
    "        \"miss European Union\"]\n",
    "\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(data)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['love', 'apple', 'juice'], tags=['0']),\n",
       " TaggedDocument(words=['love', 'orange', 'juice'], tags=['1']),\n",
       " TaggedDocument(words=['miss', 'soviet', 'union'], tags=['2']),\n",
       " TaggedDocument(words=['miss', 'european', 'union'], tags=['3'])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get word list and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love', 'apple', 'juice']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = tagged_data[0]\n",
    "doc.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> dm=1 means ‘distributed memory’ (PV-DM) and dm =0 means ‘distributed bag of words’ (PV-DBOW)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 20\n",
      "iteration 40\n",
      "iteration 60\n",
      "iteration 80\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 100\n",
    "vec_size = 20\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=1,\n",
    "                dm =1)\n",
    "  \n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    if epoch% (max_epochs/5) == 0: print('iteration {0}'.format(epoch))\n",
    "        \n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.iter)\n",
    "    \n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    \n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "model.save(\"d2v.model\")\n",
    "\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get vector representation of an unseen doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1_infer [ 0.00939252 -0.00324851 -0.00789354  0.00744676 -0.01761055  0.00213193\n",
      "  0.00639656  0.0239707  -0.00988599  0.02283477 -0.00472748  0.00618429\n",
      " -0.02016012  0.02286941  0.01486451 -0.00711495 -0.01363916  0.02092048\n",
      "  0.01515018 -0.02057129]\n",
      "\n",
      ">> vector is ready for machine learning\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "model= Doc2Vec.load(\"d2v.model\")\n",
    "#to find the vector of a document which is not in training data\n",
    "test_data = word_tokenize(\"I love chatbots\".lower())\n",
    "v1 = model.infer_vector(test_data)\n",
    "print(\"V1_infer\", v1)\n",
    "print('\\n>> vector is ready for machine learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0', 0.856641948223114), ('2', 0.7180614471435547), ('3', 0.6701167225837708)]\n"
     ]
    }
   ],
   "source": [
    "# to find most similar doc using tags\n",
    "similar_doc = model.docvecs.most_similar('1')\n",
    "print(similar_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0', 0.7460619807243347), ('2', 0.7106165289878845), ('1', 0.670116662979126)]\n"
     ]
    }
   ],
   "source": [
    "# to find most similar doc using tags\n",
    "similar_doc = model.docvecs.most_similar('3')\n",
    "print(similar_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04736115  0.01475147 -0.01801484 -0.03168618 -0.02599521  0.08510905\n",
      "  0.06087071  0.0469239   0.04417982 -0.04136113 -0.00141001  0.02436803\n",
      " -0.01150584  0.0776168   0.01904231  0.01242081  0.03733888 -0.02499858\n",
      " -0.03769484  0.01486605]\n"
     ]
    }
   ],
   "source": [
    "# to find vector of doc in training data using tags or in other words, \n",
    "# printing the vector of document at index 1 in training data\n",
    "print(model.docvecs['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1_infer [-0.01262034  0.00080706 -0.01596102  0.02155032  0.00902727 -0.01349586\n",
      " -0.02266083 -0.01867182  0.01565458  0.02170718  0.02251704  0.01250898\n",
      "  0.01488099  0.0227744   0.00697103 -0.01825041 -0.01403463  0.00473706\n",
      "  0.00092103  0.0086099 ]\n"
     ]
    }
   ],
   "source": [
    "#to find the vector of a document which is not in training data\n",
    "test_data = word_tokenize(\"fruit juice\".lower())\n",
    "v1 = model.infer_vector(test_data)\n",
    "print(\"V1_infer\", v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', -0.0534810870885849),\n",
       " ('2', -0.06103336066007614),\n",
       " ('3', -0.11242544651031494),\n",
       " ('1', -0.1933521181344986)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.most_similar([v1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('apple', 0.2626633644104004),\n",
       " ('european', -0.10963808745145798),\n",
       " ('love', -0.15924587845802307),\n",
       " ('orange', -0.1951785832643509),\n",
       " ('miss', -0.26286447048187256),\n",
       " ('juice', -0.2799147963523865),\n",
       " ('union', -0.42586463689804077)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('soviet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
